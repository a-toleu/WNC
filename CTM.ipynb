{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f90cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "newsgroups_test = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "docs = newsgroups_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600c1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library\n",
    "from CTM import *\n",
    "from tm_eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c9c1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a ctm class\n",
    "ctm = CTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91742061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "doc_clean = [ctm.clean_text(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132ba73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vocabulary extraction, optimization and vectorization\n",
    "vocab,w2vmodel, wtoi, itow = ctm.getvocab_and_vectorized(doc_clean, optimized=0, njobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ed9c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mac', 0.5695577236138913),\n",
       " ('macweek', 0.5548453866991787),\n",
       " ('hardware', 0.4888073132688122),\n",
       " ('powerpc', 0.4664941923445318),\n",
       " ('ibm', 0.4599373278135579),\n",
       " ('nubus', 0.4492192341190451),\n",
       " ('built', 0.44733814880641254),\n",
       " ('cpu', 0.43918939804266843),\n",
       " ('os', 0.43303595339317),\n",
       " ('macuser', 0.4167949704931615)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the similar words with obtained vectors\n",
    "ctm.similar_words(\"apple\", w2vmodel,wtoi,tpn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41270e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the kmeans based topic modeling\n",
    "\n",
    "topics, centroids = ctm.kMeans_tm(vocab=vocab, wtoi=wtoi, wvmodel=w2vmodel, n=20, \n",
    "                                  initA=\"random\", max_iter=1000, topM=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ce1376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : ['facility', 'empire', 'seized', 'expected', 'letter', 'gradually', 'accommodate', 'spain', 'carrier', 'month']\n",
      "topic 1 : ['bios', 'reichel', 'amour', 'formatting', 'sutter', 'explosive', 'galley', 'ottoman', 'beranek', 'physicist']\n",
      "topic 2 : ['quicktime', 'dod', 'doom', 'braking', 'ab', 'fluid', 'dot', 'deposited', 'additive', 'argument']\n",
      "topic 3 : ['american', 'former', 'seven', 'forward', 'oil', 'russian', 'working', 'sanction', 'comment', 'vat']\n",
      "topic 4 : ['people', 'going', 'know', 'investigation', 'became', 'basement', 'armored', 'something', 'come', 'head']\n",
      "topic 5 : ['arg', 'converter', 'setting', 'string', 'default', 'osf', 'resource', 'widget', 'src', 'callback']\n",
      "topic 6 : ['commercial', 'revenue', 'telecommunication', 'mariner', 'probe', 'contract', 'surface', 'venture', 'voyager', 'venus']\n",
      "topic 7 : ['award', 'date', 'special', 'avoid', 'attempt', 'supplemental', 'prompt', 'open', 'variable', 'buf']\n",
      "topic 8 : ['ontario', 'protect', 'flexible', 'device', 'specially', 'lighting', 'caveat', 'specifies', 'larger', 'canadian']\n",
      "topic 9 : ['god', 'potter', 'dialogue', 'psalm', 'matthew', 'isaiah', 'referred', 'heart', 'story', 'spoken']\n",
      "topic 10 : ['green', 'signed', 'auction', 'keith', 'miller', 'anne', 'appear', 'smith', 'ron', 'appearance']\n",
      "topic 11 : ['jpeg', 'coding', 'viewer', 'converting', 'gif', 'gifs', 'simtel', 'quality', 'color', 'ppm']\n",
      "topic 12 : ['one', 'new', 'national', 'house', 'state', 'news', 'two', 'see', 'international', 'david']\n",
      "topic 13 : ['file', 'march', 'director', 'united', 'association', 'period', 'february', 'karl', 'held', 'survey']\n",
      "topic 14 : ['report', 'april', 'child', 'nih', 'interval', 'identified', 'infected', 'selected', 'immune', 'tobacco']\n",
      "topic 15 : ['city', 'ax', 'returned', 'terrible', 'panic', 'smoked', 'school', 'organized', 'anti', 'young']\n",
      "topic 16 : ['use', 'also', 'may', 'cmu', 'address', 'name', 'used', 'get', 'program', 'site']\n",
      "topic 17 : ['username', 'anon', 'usenet', 'email', 'subdirectory', 'technology', 'service', 'message', 'xhost', 'eff']\n",
      "topic 18 : ['standing', 'rpi', 'five', 'miscellaneous', 'description', 'canada', 'professional', 'eastern', 'yale', 'hockey']\n",
      "topic 19 : ['optional', 'planned', 'hardware', 'drive', 'controller', 'rumor', 'feature', 'behave', 'floppy', 'built']\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(topics):\n",
    "    print(\"topic\",i, ':', topic[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79531341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the word network clustering (WNC) based topic modeling\n",
    "\n",
    "G, topics = ctm.build_network_and_clustering(vocab, w2vmodel, wtoi, resolution = 0.87, nodeOpti=50, ranking=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d72866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : ['would', 'way', 'well', 'year', 'without', 'work', 'world', 'want', 'written', 'yet']\n",
      "topic 1 : ['use', 'via', 'using', 'unix', 'various', 'version', 'system', 'us', 'window', 'software']\n",
      "topic 2 : ['wayne', 'york', 'trophy', 'team', 'tue', 'tampa', 'wale', 'winnipeg', 'yale', 'standing']\n",
      "topic 3 : ['volume', 'vehicle', 'space', 'venture', 'usaf', 'surveillance', 'study', 'reported', 'spain', 'venus']\n",
      "topic 4 : ['time', 'two', 'went', 'woman', 'whole', 'told', 'took', 'thing', 'see', 'three']\n",
      "topic 5 : ['war', 'zealand', 'south', 'virtually', 'university', 'ship', 'wiped', 'southern', 'secret', 'village']\n",
      "topic 6 : ['user', 'usenet', 'site', 'widespread', 'service', 'vary', 'related', 'may', 'privacy', 'telephony']\n",
      "topic 7 : ['used', 'usually', 'wire', 'wiring', 'wider', 'wall', 'trip', 'together', 'versus', 'sometimes']\n",
      "topic 8 : ['united', 'state', 'watson', 'txt', 'waiting', 'transcript', 'theatre', 'senate', 'rkba', 'union']\n",
      "topic 9 : ['working', 'think', 'specific', 'today', 'tomorrow', 'term', 'russian', 'yesterday', 'vat', 'task']\n",
      "topic 10 : ['write', 'variable', 'uuencoded', 'winner', 'section', 'supplemental', 'sure', 'program', 'rule', 'winning']\n",
      "topic 11 : ['terrible', 'rec', 'ride', 'review', 'rogers', 'motorcycle', 'stand', 'museum', 'tune', 'protector']\n",
      "topic 12 : ['thu', 'sol', 'psu', 'tad', 'msu', 'phd', 'nah', 'pb', 'npr', 'mtm']\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(topics):\n",
    "    print(\"topic\",i, ':', topic[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "680da958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing evaluation corpus\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "tokens_text = []\n",
    "for doc in docs:\n",
    "    for sent in sent_tokenize(doc):\n",
    "        words = word_tokenize(sent)\n",
    "        if len(words) > 0:\n",
    "            tokens_text.append(words)\n",
    "\n",
    "dictionary = Dictionary(tokens_text)\n",
    "bow_corpus = [dictionary.doc2bow(sent, allow_update=True) for sent in tokens_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f8024c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "umass = []\n",
    "uci = []\n",
    "cv = []\n",
    "tpns = np.arange(10,15,5)\n",
    "for tpn in tpns:\n",
    "    tc1 = Umass_coherence(topics, tpn, bow_corpus, dictionary)\n",
    "    tc2 = Uci_coherence(topics, tpn, tokens_text, dictionary)\n",
    "    tc3 = cv_coherence(topics, tpn, tokens_text,dictionary)\n",
    "\n",
    "    umass.append(tc1)\n",
    "    uci.append(tc2)\n",
    "    cv.append(tc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "645ac535",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tc = {'umass':umass,'uci':uci,'cv':cv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "846284c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'umass': [-13.89305816234572],\n",
       " 'uci': [-7.565277945544544],\n",
       " 'cv': [0.3326210811349603]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7aaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38-env",
   "language": "python",
   "name": "python38-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
